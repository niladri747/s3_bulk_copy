# S3 Transfer Data Flow Diagram

## ğŸ”„ **Small Files (< 100MB) - Single Step Transfer**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Source S3     â”‚    â”‚   EC2 Memory    â”‚    â”‚ Destination S3  â”‚
â”‚   Bucket        â”‚    â”‚   (RAM Only)    â”‚    â”‚   Bucket        â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  file.parquet   â”‚â”€â”€â”€â–¶â”‚  In-Memory      â”‚â”€â”€â”€â–¶â”‚  file.parquet   â”‚
â”‚                 â”‚    â”‚  Buffer         â”‚    â”‚                 â”‚
â”‚                 â”‚    â”‚  (~50MB)        â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
    Download              Temporary              Upload
    (source_s3)          Memory Buffer         (dest_s3)
    ~50MB â†’ RAM          (no disk)             RAM â†’ S3
```

## ğŸ”„ **Large Files (> 100MB) - Chunked Transfer**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Source S3     â”‚    â”‚   EC2 Memory    â”‚    â”‚ Destination S3  â”‚
â”‚   Bucket        â”‚    â”‚   (RAM Only)    â”‚    â”‚   Bucket        â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  large-file     â”‚â”€â”€â”€â–¶â”‚  8MB Chunks     â”‚â”€â”€â”€â–¶â”‚  large-file     â”‚
â”‚  (1GB)          â”‚    â”‚  in Memory      â”‚    â”‚  (1GB)          â”‚
â”‚                 â”‚    â”‚  (no disk)      â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
    Stream Download         Chunk Buffer          Multipart Upload
    (source_s3)            (8MB at a time)       (dest_s3)
    1GB â†’ 8MB chunks       Memory only           8MB chunks â†’ 1GB
```

## ğŸ“ **What's Stored Where**

### âœ… **EC2 Instance Storage (Disk)**
```
/opt/s3_transfer/
â”œâ”€â”€ s3_bulk_transfer.py      # Script file
â”œâ”€â”€ source_credentials.json   # Credentials
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ s3_transfer.log          # Log file
â””â”€â”€ transfer_progress.json   # Progress tracking
```

### âŒ **EC2 Instance Storage (Memory Only)**
```
RAM (Temporary):
â”œâ”€â”€ Small files: File size in memory
â”œâ”€â”€ Large files: 8MB chunks in memory
â””â”€â”€ Concurrent transfers: 8MB Ã— workers
```

### âŒ **NOT Stored on EC2**
```
âŒ No temporary files
âŒ No downloaded files on disk
âŒ No uploaded files on disk
âŒ No data persistence
```

## ğŸ§  **Memory Usage Examples**

### Example 1: 10 Small Files (50MB each)
```
Memory Usage: 50MB Ã— 10 = 500MB RAM
Disk Usage: 0MB (no files stored)
Duration: ~30 seconds per file
```

### Example 2: 1 Large File (1GB)
```
Memory Usage: 8MB chunks in RAM
Disk Usage: 0MB (no files stored)
Duration: ~5 minutes for 1GB
```

### Example 3: 5TB Transfer with 10 Workers
```
Memory Usage: 8MB Ã— 10 = 80MB RAM
Disk Usage: 0MB (no files stored)
Duration: ~2-4 hours for 5TB
```

## âš¡ **Performance Benefits**

### âœ… **Advantages**
- **No Disk I/O**: Faster than disk-based transfers
- **No Storage Requirements**: Doesn't fill up EC2 disk
- **Memory Efficient**: Only uses chunk-sized memory
- **Resume Capable**: Progress tracking without local files
- **Network Optimized**: Direct streaming

### ğŸ“Š **Speed Comparison**
```
Disk-based transfer: S3 â†’ Disk â†’ S3 (slower)
Memory-based transfer: S3 â†’ RAM â†’ S3 (faster)
```

## ğŸ”§ **Configuration Impact**

### Chunk Size Impact:
```bash
--chunk-size 8388608    # 8MB chunks (default)
--chunk-size 16777216   # 16MB chunks (faster, more memory)
--chunk-size 4194304    # 4MB chunks (slower, less memory)
```

### Workers Impact:
```bash
--max-workers 5         # 5 concurrent (40MB RAM)
--max-workers 10        # 10 concurrent (80MB RAM)
--max-workers 20        # 20 concurrent (160MB RAM)
```

## ğŸ›¡ï¸ **Security Benefits**

### âœ… **Security Advantages**
- **No Local Storage**: Data never touches EC2 disk
- **Memory Only**: Data only exists in RAM during transfer
- **Automatic Cleanup**: Memory freed after each transfer
- **No Temp Files**: No temporary files to secure/clean up

### ğŸ”’ **Data Protection**
```
Source S3 â†’ Encrypted in transit â†’ EC2 Memory â†’ Encrypted in transit â†’ Destination S3
```

## ğŸ“ˆ **Monitoring Commands**

### Memory Monitoring:
```bash
# Watch memory usage
watch -n 1 'free -h'

# Monitor Python process
ps aux | grep s3_bulk_transfer

# Check disk usage (should stay constant)
df -h
```

### Transfer Monitoring:
```bash
# Watch transfer progress
tail -f s3_transfer.log

# Check progress file
cat transfer_progress.json
```

## ğŸš¨ **Key Points**

1. **No Local Storage**: Data is never saved to EC2 disk
2. **Streaming Transfer**: Data flows through memory only
3. **Memory Efficient**: Uses minimal RAM for large files
4. **Resume Safe**: Progress tracking without local files
5. **Network Bound**: Transfer speed limited by network, not disk I/O
6. **Secure**: No data persistence on EC2 instance 